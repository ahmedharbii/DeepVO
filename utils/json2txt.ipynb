{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9nySd9_AQCr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3vYCAa2sug2"
      },
      "source": [
        "**Start from here:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0uS2sbddcHKA"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m############# Starts from here ##################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "############# Starts from here ##################\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkUDYGcgADTI"
      },
      "outputs": [],
      "source": [
        "with open('captures_000.json') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "#first remove version\n",
        "del data['version']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JLPVd63BMsb",
        "outputId": "56c8fd56-a9d7-4179-9875-cd2262916d0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1295\n"
          ]
        }
      ],
      "source": [
        "#Second remove the unrequired info from captures\n",
        "print(len(data['captures']))\n",
        "\n",
        "x_translation_list_rock = []\n",
        "y_translation_list_rock = []\n",
        "z_translation_list_rock = []\n",
        "x_rotation_list_rock = []\n",
        "y_rotation_list_rock = []\n",
        "z_rotation_list_rock = []\n",
        "w_rotation_list_rock = []\n",
        "\n",
        "x_translation_list_cam = []\n",
        "y_translation_list_cam = []\n",
        "z_translation_list_cam = []\n",
        "x_rotation_list_cam = []\n",
        "y_rotation_list_cam = []\n",
        "z_rotation_list_cam = []\n",
        "w_rotation_list_cam = []\n",
        "\n",
        "for capture in data['captures']:\n",
        "  translation = capture['sensor']['translation']\n",
        "  rotation = capture['sensor']['rotation']\n",
        "  # # print(translation)\n",
        "  x_translation_list_cam.append(translation[0])\n",
        "  y_translation_list_cam.append(translation[1])\n",
        "  z_translation_list_cam.append(translation[2])\n",
        "  x_rotation_list_cam.append(rotation[0])\n",
        "  y_rotation_list_cam.append(rotation[1])\n",
        "  z_rotation_list_cam.append(rotation[2])\n",
        "  w_rotation_list_cam.append(rotation[3])\n",
        "  # print(rotation)\n",
        "  ##Extract the rock poses\n",
        "  for annotation in capture['annotations']:\n",
        "      for value in annotation['values']:\n",
        "        translation = value['translation']\n",
        "        rotation = value['rotation']\n",
        "        # print(translation)\n",
        "        x_translation_list_rock.append(translation['x'])\n",
        "        y_translation_list_rock.append(translation['y'])\n",
        "        z_translation_list_rock.append(translation['z'])\n",
        "        x_rotation_list_rock.append(rotation['x'])\n",
        "        y_rotation_list_rock.append(rotation['y'])\n",
        "        z_rotation_list_rock.append(rotation['z'])\n",
        "        w_rotation_list_rock.append(rotation['w'])\n",
        "\n",
        "    \n",
        "  # #inside each annotation (rock_position), keep only the translations and quaternions\n",
        "  # for item in capture['annotations']:\n",
        "  #   del item['id']\n",
        "  #   del item['annotation_definition']\n",
        "    \n",
        "  #   ##inside the annotations, access the values to get only the translation and rotation\n",
        "  #   for value in a7a['values']:\n",
        "  #     del value['label_id']\n",
        "  #     del value['instance_id']\n",
        "  #     del value['size']\n",
        "  #     del value['velocity']\n",
        "  #     del value['acceleration']\n",
        "\n",
        "\n",
        "with open('rock_captures.json', 'w') as f:\n",
        "  json.dump(data, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDUMt3FNXEpt"
      },
      "outputs": [],
      "source": [
        "# x_rotation_list_cam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yH7npbOshSdR"
      },
      "outputs": [],
      "source": [
        "# x_translation_list_rock = np.array(x_translation_list_rock)\n",
        "# y_translation_list_rock = np.array(y_translation_list_rock)\n",
        "# z_translation_list_rock = np.array(z_translation_list_rock)\n",
        "# x_rotation_list_rock = np.array(x_rotation_list_rock)\n",
        "# y_rotation_list_rock = np.array(y_rotation_list_rock)\n",
        "# z_rotation_list_rock = np.array(z_rotation_list_rock)\n",
        "# w_rotation_list_rock = np.array(w_rotation_list_rock)\n",
        "\n",
        "#Converting to numpy array:\n",
        "\n",
        "x_translation_list_cam = np.array(x_translation_list_cam)\n",
        "y_translation_list_cam = np.array(y_translation_list_cam)\n",
        "z_translation_list_cam = np.array(z_translation_list_cam)\n",
        "x_rotation_list_cam = np.array(x_rotation_list_cam)\n",
        "y_rotation_list_cam = np.array(y_rotation_list_cam)\n",
        "z_rotation_list_cam = np.array(z_rotation_list_cam)\n",
        "w_rotation_list_cam = np.array(w_rotation_list_cam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHN4XvquXIGJ"
      },
      "outputs": [],
      "source": [
        "#substracting camera poses from rock poses\n",
        "#Also check the coordinates\n",
        "\n",
        "# x_translation = -x_translation_list_rock + x_translation_list_cam\n",
        "# y_translation = -y_translation_list_rock + y_translation_list_cam\n",
        "# z_translation = -z_translation_list_rock + z_translation_list_cam\n",
        "\n",
        "# q1 = -x_rotation_list_rock + x_rotation_list_cam\n",
        "# q2 = -y_rotation_list_rock + y_rotation_list_cam\n",
        "# q3 = -z_rotation_list_rock + z_rotation_list_cam\n",
        "# q4 = -w_rotation_list_rock + w_rotation_list_cam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1eYpEa0dC8m"
      },
      "outputs": [],
      "source": [
        "## Only the camera pose ##\n",
        "x_translation = x_translation_list_cam\n",
        "y_translation = y_translation_list_cam\n",
        "z_translation = z_translation_list_cam\n",
        "\n",
        "q1 = x_rotation_list_cam\n",
        "q2 = y_rotation_list_cam\n",
        "q3 = z_rotation_list_cam\n",
        "q4 = w_rotation_list_cam\n",
        "\n",
        "# pose = np.stack([ z_translation, x_translation, y_translation, q1, q2, q3, q4], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGLaSmrXKfDZ"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "timestamp = np.arange(0.0,float(len(x_translation)), )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHWNM6TxLf1j",
        "outputId": "f054ab97-f292-4273-c279-7e3ebe816298"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1295"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(timestamp)\n",
        "len(x_translation)\n",
        "# timestamp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4EarJU-ikxu"
      },
      "source": [
        "Pose File for TartanVO:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wAgjOaB2Rdr"
      },
      "source": [
        "The TUM (Technical University of Munich) format is a standard for representing 3D poses (position and orientation) in a robotics or computer vision application. It specifies a coordinate frame with the x-axis pointing to the right, the y-axis pointing up, and the z-axis pointing forward.\n",
        "\n",
        "To convert from a coordinate frame with the y-axis pointing up and the z-axis pointing forward to the TUM format, you can use a coordinate transformation matrix. This matrix will rotate the y-axis to the x-axis, the z-axis to the y-axis, and the x-axis (which was not mentioned in the original coordinate frame) to the z-axis.\n",
        "\n",
        "Here's an example of how you can define this coordinate transformation matrix in Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EftgqHlJ3AYV",
        "outputId": "d8676bdc-421d-4415-dbc5-170b6fae4bb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 1295)\n",
            "[-4.37113954e-08 -4.37113954e-08 -4.37113954e-08]\n",
            "[-1.00000012 -1.00000012 -1.00000012]\n",
            "[0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# arr = np.array([x_rotation_list_cam, y_rotation_list_cam, z_rotation_list_cam])\n",
        "# print(arr.shape)\n",
        "# for line in arr:\n",
        "#   print(line[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ9tXvs42N_V"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Define the coordinate transformation matrix\n",
        "T = np.array([[0, 0, 1],  # Rotate z-axis to y-axis\n",
        "              [1, 0, 0],  # Rotate y-axis to x-axis\n",
        "              [0, 1, 0]]) # Rotate x-axis to y-axis\n",
        "\n",
        "# Apply the coordinate transformation to a point or pose\n",
        "point = np.array([x_rotation_list_cam, y_rotation_list_cam, z_rotation_list_cam])\n",
        "point_tum = np.dot(T, point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRAWPlCo44fA"
      },
      "outputs": [],
      "source": [
        "rotation = np.array([[1 - 2*q2**2 - 2*q3**2, 2*q1*q2 - 2*q3*q4, 2*q1*q3 + 2*q2*q4],\n",
        "                     [2*q1*q2 + 2*q3*q4, 1 - 2*q1**2 - 2*q3**2, 2*q2*q3 - 2*q1*q4],\n",
        "                     [2*q1*q3 - 2*q2*q4, 2*q2*q3 + 2*q1*q4, 1 - 2*q1**2 - 2*q2**2]])\n",
        "\n",
        "# Apply the coordinate transformation to the rotation part of the pose\n",
        "rotation_tum = np.dot(T, rotation)\n",
        "\n",
        "# Concatenate the rotated rotation and the original translation to form the transformed pose\n",
        "pose_tum = np.concatenate((rotation_tum, [x_translation, y_translation, z_translation]), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmFkwEnz2cl6",
        "outputId": "bd8dd6e8-71d3-4f7e-8eee-f3093b650513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1295,)\n"
          ]
        }
      ],
      "source": [
        "print(point_tum[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUAdAjA32iMj"
      },
      "outputs": [],
      "source": [
        "pose = np.stack([point_tum[0], point_tum[1], point_tum[2], q1, q2, q3, q4], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkuD2Bf71_cg"
      },
      "source": [
        "[Conversion Left Hand Coordinates to Right](https://https://studylib.net/doc/18222978/conversion-of-left-handed-coordinates-to-right)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slNvkGfmij-M"
      },
      "outputs": [],
      "source": [
        "# Note: Going from Unity world space to ROS world space requires a conversion. Unity's coordinate space has x Right,\n",
        "# y Up, and z Forward (hence \"RUF\" coordinates); ROS has x Forward, y Left and z Up (hence \"FLU\").\n",
        "# So a Unity (x,y,z) coordinate is equivalent to the ROS (z,-x,y) coordinate. \n",
        "# These conversions are done by the To<FLU> function in the ROS-TCP-Connector package's ROSGeometry component.\n",
        "# pose = np.stack([x_translation, z_translation, y_translation, q1, q2, q3, q4], axis=1)\n",
        "\n",
        "pose = np.stack([z_translation, -x_translation, y_translation, -q1, -q2, -q3, -q4], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7ITc_9g-mDW"
      },
      "source": [
        "According to the output in the ego motion rotation [0 0 0 1], seems the convention is vector-scalar, while according to EuRoC paper, the convention in Hamilton form which is scalar-vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdWZ23yI-gm5"
      },
      "outputs": [],
      "source": [
        "pose = np.stack([z_translation, -x_translation, y_translation, -q4, -q1, -q2, -q3], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcTxEbr-FFgF"
      },
      "outputs": [],
      "source": [
        "#Second option - I checked with ROSGeometry conversion TO<FLU> in Unity\n",
        "pose = np.stack([z_translation, -x_translation, y_translation, q3, -q1, q2, q4], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RamVXAqCitc2"
      },
      "outputs": [],
      "source": [
        "np.savetxt('pose_left.txt', pose, delimiter=' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUtJ6cdLLGIC"
      },
      "source": [
        "swapped the coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pnqi7lgwGHRJ"
      },
      "outputs": [],
      "source": [
        "# pose = np.stack([x_translation, y_translation, z_translation, q1, q2, q3, q4], axis=1)\n",
        "# pose = np.stack([x_translation, z_translation, y_translation, q1, q2, q3, q4], axis=1)\n",
        "pose = np.stack([timestamp, z_translation, -x_translation, y_translation, q1, q2, q3, q4], axis=1)\n",
        "\n",
        "# pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR4NtHAaGtDb"
      },
      "outputs": [],
      "source": [
        "# from numpy import savetxt\n",
        "np.savetxt('pose_evo.txt', pose, delimiter=' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcqtggQbL7OT"
      },
      "outputs": [],
      "source": [
        "#without the camera\n",
        "\n",
        "# x_translation = -x_translation_list_rock# + x_translation_list_cam\n",
        "# y_translation = -y_translation_list_rock #+ y_translation_list_cam\n",
        "# z_translation = -z_translation_list_rock #+ z_translation_list_cam\n",
        "\n",
        "# q1 = -x_rotation_list_rock# + x_rotation_list_cam\n",
        "# q2 = -y_rotation_list_rock# + y_rotation_list_cam\n",
        "# q3 = -z_rotation_list_rock# + z_rotation_list_cam\n",
        "# q4 = -w_rotation_list_rock# + w_rotation_list_cam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIGqwnYX_XBb"
      },
      "outputs": [],
      "source": [
        "tartan_result = np.loadtxt('unity_vo_model_pretrained.txt', delimiter=' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S-r-9KY_yP3",
        "outputId": "6ddbb519-8dd2-49da-aa7d-9ef7e129cca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "timestamp shape (10001,)\n",
            "timestamp shape after expanding the dimensions (10001, 1)\n",
            "pose shape (10001, 7)\n"
          ]
        }
      ],
      "source": [
        "print('timestamp shape', timestamp.shape)\n",
        "timestamp2 = np.expand_dims(timestamp, axis=1)\n",
        "print('timestamp shape after expanding the dimensions', timestamp2.shape)\n",
        "print('pose shape', tartan_result.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr0BNs6M_oqZ"
      },
      "outputs": [],
      "source": [
        "tartan_result = np.concatenate((timestamp2, tartan_result), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bittCVM3xZX"
      },
      "outputs": [],
      "source": [
        "np.savetxt('tartan_evo.txt', tartan_result, delimiter=' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elPVs37b6NyZ"
      },
      "outputs": [],
      "source": [
        "# tartan_result = pd.read_csv('unity_tartanvo_1914.csv', delimiter=' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65TOqrd_-FNW"
      },
      "outputs": [],
      "source": [
        "# a7a.insert(0, column = 0, value = timestamp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuzHSKlG5ofu"
      },
      "outputs": [],
      "source": [
        "# a7a.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv_ur5e",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c50c335c4739e50ef05af5275fc91e5174564c9ca639876b15405591496d69da"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
